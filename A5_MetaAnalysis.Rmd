---
title: "Assignment 5 - Meta-analysis of pitch in schizophrenia"
author: "Riccardo Fusaroli"
date: "3/7/2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r loading packages, include = FALSE}
library(pacman)
p_load(ggplot2, lme4, stringr, dplyr, reshape2, growthcurver, purrr, modelr, Metrics, caret, simr, stats, FinCal, nonlinearTseries, scales, GMCM, pROC, gridExtra, groupdata2, crqa, tidyr, ggbeeswarm, plotrix, metafor, lmerTest, Hmisc)
```

# Building on the shoulders of giants: meta-analysis

## Questions to be answered

1. What is the current evidence for distinctive patterns of pitch mean and pitch sd in schizophrenia? Report how many papers report quantitative estimates, your method to analyze them, the estimated effect size of the difference (mean effect size and standard error for pitch mean, same for pitch sd) and forest plots representing it. 

After a review of the studies associated with measurements of pitch in relation to the diagnosis schizophrenia, we excluded studies, we found unsuited. Using metafor to calculate yi (mean effect size) and vi (standard error) for both pitch mean and pitch sd, we made a linear regression to create a forest plot. 

5 paper investigate the effect of mean pitch in relation to the diagnosis schizophrenia, however, one is excluded due to measurements in the unit, semitones. These four point to an effect of higher mean pitch (yi = 0.24, 95% CIs: -0.22, 0.71), if you are diagnosed with schizophrenia. However, the effect size is relatively small with a slight chance of no effect at all, since the summed effect size crosses the point of zero. 

```{r to make the plot, include = FALSE}
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio 4/Portfolio_4")
p_data <- read.csv("SR_SCHIZO.csv")

#using the metaphor package to calculate iy and vi

#FUNDAMENTAL FREQUENCY

#The "yi" variable is the z score transformation (effect size) and the "vi" variable is the corresponding estimated sampling variance.
p_data_mean=escalc('SMD', n1i=p_data$SAMPLE_SIZE_SZ, n2i=p_data$SAMPLE_SIZE_HC, m1i=p_data$PITCH_F0_SZ_M, m2i=p_data$PITCH_F0_HC_M, sd1i=p_data$PITCH_F0_SZ_SD, sd2i=p_data$PITCH_F0_HC_SD, data = p_data)


#finding complete cases
CompCases <- complete.cases(p_data_mean$PITCH_F0_HC_M)
CompCases <- cbind(p_data_mean, CompCases)
p_data_m <- filter(CompCases, CompCases == "TRUE")

#excluding
p_data_mean <- p_data_m[-4,] #measured in semitones, not hz


#mixed effects implementation
Model_mean <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_mean,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_mean <- rma(yi, vi, data = p_data_mean, slab=Article)


#VARIABILITY
#The "yi" variable is the z score transformation and the "vi" variable is the corresponding estimated sampling variance.
p_data_variability=escalc('SMD', n1i=p_data$SAMPLE_SIZE_SZ, n2i=p_data$SAMPLE_SIZE_HC, m1i=p_data$PITCH_F0SD_SZ_M,
m2i=p_data$PITCH_F0SD_HC_M, sd1i=p_data$PITCH_F0SD_SZ_SD, sd2i=p_data$PITCH_F0SD_HC_SD, data = p_data)

#Finding complete cases
CompCases <- complete.cases(p_data_variability$PITCH_F0SD_HC_M)
CompCases <- cbind(p_data_variability, CompCases)
p_data_variability <- filter(CompCases, CompCases == "TRUE")

#excluding
p_data_variability <- p_data_variability[-c(2, 3, 6, 7, 10, 13, 14),] #frequency not specified or measured in semitones


#mixed effects implementation
Model_variability <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_variability,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))


#Meta-analysis optimization
Model_variability <- rma(yi, vi, data = p_data_variability, slab=Article)

```


```{r, echo = FALSE}
forest(Model_mean)
```


14 papers investigate variability in pitch in relation to the diagnosis, schizophrenia. 7 was excluded due to measurements in different units e.g. semitones or unreported units. The remaining 7 studies point to an effect of smaller variability in pitch, if you have the diagnosis, schizophrenia (yi = -0.53, 95% CIs: -0.94, -0.13). 
 
```{r, echo = FALSE}
forest(Model_variability)
```

2. Do the results match your own analysis from Assignment 3? If you add your results to the meta-analysis, do the estimated effect sizes change? Report the new estimates and the new forest plots.

The results from our own analysis in assignment 3 do to a large extend match up to the tendencies from the resuming studies. For the effect of mean pitch including our own analysis, we find that a diagnosis of schizophrenia is related to a higher mean pitch (yi = 0.23, 95% CIs: -0.04, 0.50). 

```{r forest plots including our studies, echo = FALSE}
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2/")

p_data_mean <- read.csv("p_data_m")
p_data_variability <- read.csv("p_data_sd")

#mixed effects implementation
Model_mean <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_mean,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_mean <- rma(yi, vi, data = p_data_mean, slab=Article)

forest(Model_mean)
```

For the effect of variability including our own analysis, we find that a diagnosis of schizephrenia is related to lower variability (yi = -044, 95% CIs: -0.73, -0.16)

```{r forest plot for variability, echo = FALSE}
#mixed effects implementation
Model_variability <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_variability,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_variability <- rma(yi, vi, data = p_data_variability, slab=Article)

forest(Model_variability)
```


3. Assess the quality of the literature: report and comment on heterogeneity of the studies (tau, I2), on publication bias (funnel plot), and on influential studies.

We calculated overall variance for the effect of pitch mean and variability (τ2) and assessed whether it could be explained by within-study variance (e.g., due to measurement noise or heterogeneity in the SZ samples included in the studies) using Cochran’s Q (Cochran, 1954) and I2 statistics (Higgins, Thompson, Deeks, & Altman, 2003)

The overall variance for the effect of pitch mean (τ2) was 0.68 (95% CIs: 0.27 2.85). Much of the variance (I2: 96.28%, 95% CIs: 91.13 99.08) could not be reduced to random sample variability between studies (Q-stats = 488.5384, p < 0.0001).

The overall variance for the effect of pitch variability (τ2) was 1.12 (95% CIs: 0.60 2.86). Much of the variance (I2: 97.03%, 95% CIs: 94.57 98.80) could not be reduced to random sample variability between studies (Q-stats = 267.71, p < 0.0001).

We could impute further studies to even out the publication biases, however this would assume our estimated 'real' effect size is true. This assumption is not necessarily valid. 

The heterogenety is clearly visible in the funnelplot below of the effect of pitch mean. 

```{r funnelplot2, echo = FALSE}

### set up 1x1 array for plotting
par(mfrow=c(1,1))
 
### draw funnel plots
funnel(Model_mean, main="Standard Error")

```

The same accounts for the effect of variability. The heterogenety is clearly visible in the funnelplot below. 

```{r, echo = FALSE}
### draw funnel plots
funnel(Model_variability, main="Standard Error")
```

When testing for influential studies we find the for the effect of mean that Martinez-Sánchez et al. (2015) is very influential and very different. To check if this should be excluded, you could review the article to see, if they have good methods. If not it should be excluded. 

```{r, echo = FALSE}
inf_m <- influence(Model_mean)
plot(inf_m)
```

The same accounts for Ross et al. (2001)_1 in studies investigating the effect of variability in pitch. 

```{r, echo = FALSE}
inf_sd <- influence(Model_variability)
plot(inf_sd)
```


Link to GitHub: https://github.com/KiriKoppelgaard/Portfolio_4

## Tips on the process to follow:

- Download the data on all published articles analyzing pitch in schizophrenia (on gitlab)
```{r load data, include = FALSE}
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio 4/Portfolio_4")
p_data <- read.csv("SR_SCHIZO.csv")
```

- Look through the dataset to find out which columns to use, and if there is any additional information written as comments (real world data is always messy!).
    * Hint: Make sure you read the comments in the columns: `pitch_f0_variability`, `frequency`, `Title`,  `ACOUST_ANA_DESCR`, `DESCRIPTION`, and `COMMENTS`
    
    
    F0 = fundamental frequency, the number of vocal fold vibrations per unit of time
    SZ = skitzofrenic
    HC = Normal
    
```{r data cleaning, include = FALSE}
p_data$frequency[2] <- 'hz'
```

- Following the procedure in the slides calculate effect size (yi) and standard error (vi) of the effect size per each study. N.B. we focus on pitch mean and pitch standard deviation.
```{r calculating effect size and sd, include = FALSE}
#using the metaphor package to calculate iy and vi

#FUNDAMENTAL FREQUENCY

#The "yi" variable is the z score transformation (effect size) and the "vi" variable is the corresponding estimated sampling variance.
p_data_mean=escalc('SMD', n1i=p_data$SAMPLE_SIZE_SZ, n2i=p_data$SAMPLE_SIZE_HC, m1i=p_data$PITCH_F0_SZ_M,
m2i=p_data$PITCH_F0_HC_M, sd1i=p_data$PITCH_F0_SZ_SD, sd2i=p_data$PITCH_F0_HC_SD, data = p_data)


#finding complete cases
CompCases <- complete.cases(p_data_mean$PITCH_F0_HC_M)
CompCases <- cbind(p_data_mean, CompCases)
p_data_mean <- filter(CompCases, CompCases == "TRUE")

#excluding
p_data_mean <- p_data_mean[-4,] #measured in semitones, not hz


#mixed effects implementation
Model_mean <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_mean,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_mean <- rma(yi, vi, data = p_data_mean, slab=Article)


#VARIABILITY
#The "yi" variable is the z score transformation and the "vi" variable is the corresponding estimated sampling variance.
p_data_variability=escalc('SMD', n1i=p_data$SAMPLE_SIZE_SZ, n2i=p_data$SAMPLE_SIZE_HC, m1i=p_data$PITCH_F0SD_SZ_M,
m2i=p_data$PITCH_F0SD_HC_M, sd1i=p_data$PITCH_F0SD_SZ_SD, sd2i=p_data$PITCH_F0SD_HC_SD, data = p_data)

#Finding complete cases
CompCases <- complete.cases(p_data_variability$PITCH_F0SD_HC_M)
CompCases <- cbind(p_data_variability, CompCases)
p_data_variability <- filter(CompCases, CompCases == "TRUE")

#excluding
p_data_variability <- p_data_variability[-c(2, 3, 6, 7, 10, 13, 14),] #frequency not specified or measured in semitones


#mixed effects implementation
Model_variability <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_variability,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))


#Meta-analysis optimization
Model_variability <- rma(yi, vi, data = p_data_variability, slab=Article)

```

 . first try using lmer (to connect to what you know of mixed effects models)
 . then use rma() (to get some juicy additional statistics)

- Build a forest plot of the results (forest(model))
```{r, echo = FALSE, include = FALSE}
forest(Model_mean)

forest(Model_variability)
```

 
- Go back to Assignment 3, add your own study to the data table, and re-run meta-analysis. Do the results change?

```{r extracting data from assignment 3, include = FALSE}
#loading data from assignment 3.1
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2")

pitch_data <- read.csv("pitch_data.csv")

#defining models from the assignment
model_mean <-lmer(mean ~ diagnosis + Gender  + (1+trial|Subject) + (1+trial|study), data = pitch_data, REML = FALSE)

model_sd <-lmer(sd ~ diagnosis + Gender  + (1+trial|Subject) + (1+trial|study), data = pitch_data, REML = FALSE)

#creating empty dataframe with column names to match the current data
p3_data <- data.frame(matrix(ncol = 13, nrow = 3))

x <- c("frequency", "StudyID", "Article", "SAMPLE_SIZE_SZ", "SAMPLE_SIZE_HC", "PITCH_F0_HC_M", "PITCH_F0_HC_SD", "PITCH_F0_SZ_M", "PITCH_F0_SZ_SD", "PITCH_F0SD_HC_M", "PITCH_F0SD_HC_SD", "PITCH_F0SD_SZ_M", "PITCH_F0SD_SZ_SD")

colnames(p3_data) <- x

#making a prediction matrix
df = distinct(pitch_data, diagnosis, study, Gender) %>%
  mutate(trial = mean(pitch_data$trial)) %>%
  filter(complete.cases(Gender))

df

df$pred <- predict(model_mean, newdata = df, re.form = ~ (1|study), allow.new.levels = TRUE)

df

#making predictions for mean when the other are constant
df = df %>% group_by(diagnosis, study)%>%
  summarise(m = mean(pred), 
            sd = sd(pred))

df

#inserting the predictions into the dataframe
p3_data$PITCH_F0_HC_M <- df$m[1:3]
p3_data$PITCH_F0_SZ_M <- df$m[4:6]


#inserting sd of the predictions
p3_data$PITCH_F0_HC_SD <- df$sd[1:3]
p3_data$PITCH_F0_SZ_SD <- df$sd[4:6]

#making predictions for sd, when the other effects of the model is constant
df = distinct(pitch_data, diagnosis, study, Gender) %>%
  mutate(trial = mean(pitch_data$trial)) %>%
  filter(complete.cases(Gender))

df$pred <- predict(model_sd, newdata = df, re.form = ~ (1|study), allow.new.levels = TRUE)

df = group_by(df, diagnosis, study) %>%
  summarise(m = mean(pred),
            sd = sd(pred))


#inserting data into the dataframe
p3_data$PITCH_F0SD_HC_M <- df$m[1:3]
p3_data$PITCH_F0SD_SZ_M <- df$m[4:6]

p3_data$PITCH_F0SD_HC_SD <- df$sd[1:3]
p3_data$PITCH_F0SD_SZ_SD <- df$sd[4:6]

#defining the other factors

p3_data$frequency <- "hz"

p3_data$StudyID <- c("49", "50", "51")

p3_data$Article <- "Koppelgaard et al"


#Calculating sample size
#sample_size <- pitch_data %>% group_by(study, diagnosis)%>% summarize(n())

p3_data$SAMPLE_SIZE_HC <- c(36, 23, 16)

p3_data$SAMPLE_SIZE_SZ <- c(34, 23, 19)


#calculating vi and yi
p3_data_mean=escalc('SMD', n1i=SAMPLE_SIZE_HC, n2i=SAMPLE_SIZE_SZ, m1i=PITCH_F0_SZ_M,
m2i=PITCH_F0_HC_M, sd1i=PITCH_F0_HC_SD, sd2i=PITCH_F0_SZ_SD,
data = p3_data)

#calculating vi and yi
p3_data_variability=escalc('SMD', n1i=SAMPLE_SIZE_HC, n2i=SAMPLE_SIZE_SZ, m1i=PITCH_F0SD_SZ_M,
m2i=PITCH_F0SD_HC_M, sd1i=PITCH_F0SD_HC_SD, sd2i=PITCH_F0SD_SZ_SD,
data = p3_data)

#Save csv, before loading plyr
write.csv(p3_data_variability, "p3_data_sd")
write.csv(p3_data_mean, "p3_data_m")

```



```{r binding the data, include=FALSE, eval = FALSE}
library(plyr)

#rbinding the new dataset
p_data_mean <- rbind.fill(p_data_mean, p3_data_mean)

#rbinding the new dataset
p_data_variability <- rbind.fill(p_data_variability, p3_data_variability)

#save csv
write.csv(p_data_mean, "p_data_m")
write.csv(p_data_variability, "p_data_sd")

```



```{r plotting the effect size of assignment 3, echo = FALSE, include = FALSE}
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2/")
p_data_mean <- read.csv("p_data_m")
p_data_variability <- read.csv("p_data_sd")


ggplot(p3_data_mean, aes(x = StudyID, y = yi ))  + #creating barplot and choosing axes
  geom_bar(stat = "summary", fun.y = mean, aes(fill = StudyID)) + #adding barplot-layer 
  geom_errorbar(stat = "summary", fun.data = mean_cl_boot, width = 0.2) + #Adding confidence intervals
  labs( title = "Effect size for the effect of pitch mean") # adding labels


ggplot(p3_data_variability, aes(x = StudyID, y = yi ))  + #creating barplot and choosing axes
  geom_bar(stat = "summary", fun.y = mean, aes(fill = StudyID)) + #adding barplot-layer with the y-axes as the mean of           tongue_twister and colour
  geom_errorbar(stat = "summary", fun.data = mean_cl_boot, width = 0.2) + #Adding confidence intervals
  labs( title = "Effect size for the effect of pitch variability") # adding labels

```


```{r rerunning the analysis, include = FALSE}

#mixed effects implementation
Model_mean <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_mean,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_mean <- rma(yi, vi, data = p_data_mean, slab=StudyID)

#mixed effects implementation
Model_variability <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=p_data_variability,
control=lmerControl(check.nobs.vs.nlev="ignore",
check.nobs.vs.nRE="ignore"))

#Meta-analysis optimization
Model_variability <- rma(yi, vi, data = p_data_variability, slab=StudyID)

```


```{r new forest plots, echo = FALSE, include = FALSE}
forest(Model_mean)

forest(Model_variability)
```


- Now look at the output of rma() and check tau and I2

```{r calculating confidence intervals, include = FALSE}
Model_mean
Model_variability

confint(Model_mean)
confint(Model_variability)

```


```{r funnelplot, echo = FALSE, include = FALSE}

### set up 1x1 array for plotting
par(mfrow=c(1,1))
 
### draw funnel plots
funnel(Model_mean, main="Standard Error")

### draw funnel plots
funnel(Model_variability, main="Standard Error")

```


Testing influential studies

```{r, include = FALSE}
inf_m <- influence(Model_mean)
print(inf_m)
plot(inf_m)

inf_sd <- influence(Model_variability)
print(inf_sd)
plot(inf_sd)



# https://www.rdocumentation.org/packages/metafor/versions/1.9-9/topics/influence.rma.uni
```



